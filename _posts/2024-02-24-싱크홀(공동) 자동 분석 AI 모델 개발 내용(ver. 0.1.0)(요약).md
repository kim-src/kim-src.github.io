---
title: ì‹±í¬í™€(ê³µë™) ìë™ ë¶„ì„ AI ëª¨ë¸ ê°œë°œ ë‚´ìš©(ver. 0.1.0)(ìš”ì•½)
date: 2024-02-24 21:00:00 +09:00
categories: [VisualCavity, AI Model]
tags: [Python, TensorFlow, AI, AI Model, Numpy, VisualCavity]
---

<!-- 2024-02-19 ê¸€ ì‘ì„± ì‹œì‘; 2024-02-20 í˜ì´ì§€ í˜¸ì¶œ ì™„ë£Œ -->
# âœ… ì‹±í¬í™€(ê³µë™) ìë™ ë¶„ì„ AI ëª¨ë¸ VisualCavity AI(ìš”ì•½)

<br>

### ğŸ”” 1. Introduction
### ğŸ“Œ ëª¨ë¸ ì†Œê°œ
> - ëª¨ë¸ëª… : VisualCavity (ver. 0.1.0)
> - ëª¨ë¸ë¶„ë¥˜ : ì´ë¯¸ì§€ í•™ìŠµ CNN AI ëª¨ë¸
> - ìƒì„¸ë‚´ìš© : ì‹±í¬í™€(ê³µë™) ìë™ ë¶„ì„ í”„ë¡œê·¸ë¨ ì œì‘ì„ ìœ„í•œ ì´ë¯¸ì§€ í•™ìŠµ AI ëª¨ë¸
> - ê°œë°œëª©ì  : 3D-GPR ë°ì´í„° ë¶„ì„ ë‚œì´ë„ í•˜í–¥
> - ì£¼ìš”ìë£Œ : GPR ê³µë™ íƒì‚¬ ë°ì´í„° ë° 30ë§Œì¥ì˜ ì´ë¯¸ì§€

<br>

### ğŸ”” 2. Methodology
### ğŸ“Œ ê°œë°œ í™˜ê²½
> - Google Colabì—ì„œ Python ì½”ë“œë¥¼ ì‘ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.
> - ì£¼ë¡œ ì‚¬ìš©ëœ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” TensorFlow, OpenCV ì…ë‹ˆë‹¤.

### ğŸ“Œ ì´ë¯¸ì§€ í•™ìŠµì„ ìœ„í•œ ì½”ë”© ìˆœì„œ
>   1. Python ë‚´ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
>   2. í•™ìŠµì‹œí‚¬ ì´ë¯¸ì§€ 1ì¥ì— ëŒ€í•œ JPG ë° XML íŒŒì¼ì˜ ê²½ë¡œ ì„¤ì •
>   3. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ í•¨ìˆ˜ ì •ì˜
>   4. ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ í•¨ìˆ˜ ì‘ì„±
>   5. XML íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ì •ë³´ ìŠµë“ì„ ìœ„í•œ í•¨ìˆ˜ ì •ì˜
>   6. XML íŒŒì¼ì„ íŒŒì‹± í›„ ë°ì´í„° ì¶”ì¶œ
>   7. CNN ëª¨ë¸ êµ¬ì„±(CNN : ì»¨ë³¼ë£¨ì…˜ ì‹ ê²½ë§ : Convolution Neural Network)
>   8. ëª¨ë¸ ì»´íŒŒì¼(Compile : ì‚¬ëŒì´ ì‘ì„±í•œ ì½”ë“œë¥¼ ì»´í“¨í„°ì—ê²Œ ì´í•´ì‹œí‚¤ëŠ” ê³¼ì •)
>   9. ëª¨ë¸ì— ì…ë ¥í•  ì´ë¯¸ì§€ ë° ë ˆì´ë¸” ë°ì´í„° ì„¸íŒ…
>   10. ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ë§ê²Œ í˜•íƒœ ë³€í™˜
>   11. ëª¨ë¸ í›ˆë ¨(epochs í™œìš©)

<br>

### ğŸ”” 3. Results : ì „ì²´ ì½”ë“œ
### ğŸ“Œ ì´ë¯¸ì§€ í•™ìŠµì— ì‚¬ìš©ëœ ì½”ë“œ ë° ê°„ëµí•œ ì„¤ëª…
> - ì´ë¯¸ì§€ í•™ìŠµì— ì‚¬ìš©ëœ ì „ì²´ì ì¸ ì½”ë“œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.
> - ê° ì½”ë“œë§ˆë‹¤ ê°„ëµí•œ ì„¤ëª…ì„ ì‘ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.
> - ê° ì½”ë“œì™€ ê´€ë ¨ëœ ìƒì„¸í•œ ì„¤ëª…ì€ ë‹¤ìŒ ê¸€ì— ì‘ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.

### ğŸ“Œ AI ëª¨ë¸ì˜ ì´ë¯¸ì§€ í•™ìŠµì„ ìœ„í•œ Python ì½”ë“œ
```python
# Python ë‚´ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
import xml.etree.ElementTree as ET  # XML íŒŒì¼ì„ íŒŒì‹±í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
import cv2  # ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ì»´í“¨í„° ë¹„ì „ ì‘ì—…ì„ ìœ„í•œ OpenCV ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
import numpy as np  # ì´ë¯¸ì§€ ë°°ì—´ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
import tensorflow as tf  # ë”¥ëŸ¬ë‹ ëª¨ë¸ êµ¬ì¶•ì„ ìœ„í•œ TensorFlow ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
from tensorflow.keras import layers, models  # ëª¨ë¸ì˜ ë ˆì´ì–´ë¥¼ ì ìš©í•˜ê¸° ìœ„í•´ TensorFlowì˜ Keras APIë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
from tensorflow.keras.preprocessing import image  # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
from tensorflow.keras.preprocessing.image import img_to_array  # ì´ë¯¸ì§€ë¥¼ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.

# í•™ìŠµì‹œí‚¬ ì´ë¯¸ì§€ 1ì¥ì— ëŒ€í•œ JPG ë° XML íŒŒì¼ì˜ ê²½ë¡œ ì„¤ì •
image_path = "/content/drive/MyDrive/MyPJT/Cavity_PJT/cavity_sample_img.jpg" # JPG íŒŒì¼ ê²½ë¡œì…ë‹ˆë‹¤.
xml_path = "/content/drive/MyDrive/MyPJT/Cavity_PJT/cavity_sample_xml.xml" # XML íŒŒì¼ ê²½ë¡œì…ë‹ˆë‹¤.

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ í•¨ìˆ˜ ì •ì˜
def preprocess_image(image_path, target_size=(256, 256)):
    img = image.load_img(image_path, target_size=target_size)  # ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³  target_sizeë¡œ í¬ê¸°ë¥¼ ì¡°ì •í•˜ì˜€ìŠµë‹ˆë‹¤.
    img_array = img_to_array(img)  # ì´ë¯¸ì§€ ë°°ì—´ì„ Numpyì— ë§ê²Œ ë³€í™˜í•˜ì˜€ìŠµë‹ˆë‹¤.
    img_array = np.expand_dims(img_array, axis=0)  # ì´ë¯¸ì§€ ë°°ì—´ ê´€ë ¨ ë°°ì¹˜ ì°¨ì›ì„ ì¶”ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.
    img_array /= 255.0  # ì´ë¯¸ì§€ë¥¼ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ì •ê·œí™”(ì¤‘ë³µ ì œê±°)í•˜ì˜€ìŠµë‹ˆë‹¤.
    return img_array  # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ë©´, ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ì˜ ë°°ì—´ì„ ë°˜í™˜í•˜ë„ë¡ í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ì˜€ìŠµë‹ˆë‹¤.

# ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ í•¨ìˆ˜ ì‘ì„±
img_array = preprocess_image(image_path) # ìƒê¸° ì •ì˜í•œ í•¨ìˆ˜ì— ëŒ€í•œ ë‚´ìš©ì„ ì‘ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.

# XML íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ì •ë³´ íŒŒì‹±ì„ ìœ„í•œ í•¨ìˆ˜ ì •ì˜(íŒŒì‹± : í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒ)
def parse_annotation(xml_path):
    tree = ET.parse(xml_path)  # ElementTreeë¡œ XML íŒŒì¼ì„ íŒŒì‹±í•˜ì˜€ìŠµë‹ˆë‹¤.
    root = tree.getroot()  # íŒŒì‹±ëœ XML íŒŒì¼ì— ë£¨íŠ¸ ì—˜ë¦¬ë¨¼íŠ¸ë¥¼ ì ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.

    filename = root.find('filename').text  # ì´ë¯¸ì§€ì˜ ë°ì´í„°ì˜ ì´ë¦„ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.
    object_name = root.find('.//object/name').text  # ê°ì²´ì˜ ì´ë¦„ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.

    # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ì¶”ì¶œ(ROI : Region of Interst)
    xmin = float(root.find('.//bndbox/xmin').text)
    ymin = float(root.find('.//bndbox/ymin').text)
    xmax = float(root.find('.//bndbox/xmax').text)
    ymax = float(root.find('.//bndbox/ymax').text)

    return filename, object_name, xmin, ymin, xmax, ymax # ì´ë¯¸ì§€ íŒŒì‹±ì´ ì™„ë£Œë˜ë©´ ê´€ë ¨ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ë„ë¡ í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ì˜€ìŠµë‹ˆë‹¤.

# XML íŒŒì¼ì„ íŒŒì‹± í›„ ë°ì´í„° ì¶”ì¶œ
filename, object_name, xmin, ymin, xmax, ymax = parse_annotation(xml_path)

# CNN ëª¨ë¸ êµ¬ì„±(CNN : ì»¨ë³¼ë£¨ì…˜ ì‹ ê²½ë§ : Convolution Neural Network)
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())  # AI ëª¨ë¸ì— í‰íƒ„í™”(Flatten) ë ˆì´ì–´ë¥¼ ì¶”ê°€í•˜ê¸° ìœ„í•´ 3D íŠ¹ì„± ë§µì„ 1D í…ì„œë¡œ í‰íƒ„í™”í•˜ì˜€ìŠµë‹ˆë‹¤.
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))  # ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì¶œë ¥ ë ˆì´ì–´ë¥¼ ì¶”ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.

# ëª¨ë¸ ì»´íŒŒì¼(Compile : ì‚¬ëŒì´ ì‘ì„±í•œ ì½”ë“œë¥¼ ì»´í“¨í„°ì—ê²Œ ì´í•´ì‹œí‚¤ëŠ” ê³¼ì •)
model.compile(optimizer='adam',
              loss='binary_crossentropy',  # ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
              metrics=['accuracy'])  # ì •í™•ë„(accuracy)ë¥¼ í‰ê°€ ì§€í‘œ(metrics)ë¡œ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.

# ëª¨ë¸ì— ì…ë ¥í•  ì´ë¯¸ì§€ ë° ë ˆì´ë¸” ë°ì´í„° ì„¸íŒ…
X_train = np.array([img_array])  # ì´ë¯¸ì§€ ë°°ì—´ì„ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜í•˜ê²Œ í•˜ì˜€ìŠµë‹ˆë‹¤.
y_train = np.array([1])  # ì´ì§„ ë¶„ë¥˜ì˜ ê²½ìš° ë ˆì´ë¸”ì„ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜í•˜ê²Œ í•˜ì˜€ìŠµë‹ˆë‹¤.

# ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ë§ê²Œ í˜•íƒœ ë³€í™˜
X_train = np.squeeze(X_train, axis=0)

# ëª¨ë¸ í›ˆë ¨(Epochs í™œìš©)
model.fit(X_train, y_train, epochs=5, batch_size=1)
```

<br>

### ğŸ”” 4. Conclustions
### ğŸ“Œ AI ëª¨ë¸ì˜ ì´ë¯¸ì§€ í•™ìŠµ í˜„í™© íŒë‹¨ ë°©ë²•
> - Pythonì„ ì´ìš©í•œ CNN AI ëª¨ë¸ì˜ ì´ë¯¸ì§€ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìœ¼ë©° ì´ ì´ë¯¸ì§€ í•™ìŠµì€ ë¨¸ì‹  ëŸ¬ë‹ì˜ ì¼í™˜ì…ë‹ˆë‹¤.
> - ë¨¸ì‹  ëŸ¬ë‹ ì¤‘ AI ì´ë¯¸ì§€ í•™ìŠµ ê²°ê³¼ëŠ” Epochë¡œ íŒë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> - Epoch=1ì€ ë¨¸ì‹  ëŸ¬ë‹ì˜ ì‹ ê²½ë§(Neural Network)ì´ ë°ì´í„° ì„¸íŠ¸ë¥¼ í•œ ë²ˆ í†µê³¼í•˜ëŠ” ê³¼ì •ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
> - ë³¸ AI ëª¨ë¸ì˜ EpochsëŠ” 5ë¡œ ì„¤ì •í–ˆê¸° ë•Œë¬¸ì— ì‹ ê²½ë§ì´ ì „ì²´ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë‹¤ì„¯ ë²ˆ í†µê³¼í•˜ì˜€ìŠµë‹ˆë‹¤.
> - ì•„ë˜ëŠ” 5ë²ˆì˜ Epochë¡œ íŒë‹¨í•  ìˆ˜ ìˆëŠ” AI ëª¨ë¸ì˜ ì´ë¯¸ì§€ í•™ìŠµ í˜„í™©ì…ë‹ˆë‹¤.

### ğŸ“Œ Epochë¡œ ì•Œì•„ë³´ëŠ” AI ëª¨ë¸ì˜ ì´ë¯¸ì§€ í•™ìŠµ í˜„í™©
> - Epoch 1/5 : AI ëª¨ë¸ì´ ë°ì´í„°ë¥¼ 2ì´ˆ ë™ì•ˆ í•œ ë²ˆ í†µê³¼í•˜ì˜€ê³  ì •í™•ë„ëŠ” 100% (= 1)ì…ë‹ˆë‹¤.
> - Epoch 2/5 : AI ëª¨ë¸ì˜ í•™ìŠµ ì •í™•ë„ê°€ 100% ìœ ì§€ë˜ì—ˆê³  ì†ì‹¤ ì •ë„ëŠ” 0ì— ê°€ê¹ìŠµë‹ˆë‹¤.
> - Epoch 3/5 ~ 5/5 : AI ëª¨ë¸ì˜ í•™ìŠµ ì •í™•ë„ê°€ 100%ì´ê³  ì†ì‹¤ ì •ë„ëŠ” 0ì…ë‹ˆë‹¤.
> - Epoch ê°’ ìì²´ë¡œë§Œ ë´¤ì„ ë•ŒëŠ” AI ëª¨ë¸ì— ì´ë¯¸ì§€ê°€ ì™„ë²½íˆ í•™ìŠµë˜ì—ˆë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ“Œ AI ëª¨ë¸ì˜ ì´ë¯¸ì§€ í•™ìŠµ ê²°ê³¼ í•´ì„
> - ì •ëŸ‰ì ì¸ Epoch ê²°ê³¼ëŠ” ì™„ë²½í•˜ì§€ë§Œ ì •ì„±ì ìœ¼ë¡œ í‰ê°€í•˜ì˜€ì„ ë•Œ ì´ ëª¨ë¸ì€ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.
> - ë‹¤ì–‘ì„± ë¶€ì¡± : ì´ë¯¸ì§€ ë°ì´í„°ê°€ ìœ ì‚¬í•œ ê²½ìš° AI ëª¨ë¸ì´ ì‰½ê²Œ ë°ì´í„° íŒ¨í„´ì„ í•™ìŠµí–ˆì„ ê²ƒì…ë‹ˆë‹¤.
> - ê³¼ì í•© : AI ëª¨ë¸ì´ ì´ë¯¸ì§€ ë°ì´í„°ì— ê³¼ë„í•˜ê²Œ fitting ë˜ì–´ ìˆì–´ì„œ ì¼ë°˜í™”ë˜ì§€ ì•Šì€ ê²ƒ ê°™ìŠµë‹ˆë‹¤.
> - AI ëª¨ë¸ì˜ í•™ìŠµ ì •ë„ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ê²€í† í•˜ê¸° ìœ„í•´ì„œëŠ” Validation ë°ì´í„° ì—­ì‹œ í™œìš©ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
> - ë¶€ë¡ ë‚´ìš©ê³¼ ê°™ì´ AI ëª¨ë¸ì˜ ë²„ì „ì„ ì—…ê·¸ë ˆì´ë“œí•˜ë©° ì •ëŸ‰ì ì¸ í‰ê°€ë¥¼ í•  í•„ìš”ì„±ì´ ìˆìŠµë‹ˆë‹¤.
> - ë‹¤ìŒ ê¸€ì— ì—…ê·¸ë ˆì´ë“œ ë²„ì „ì— ëŒ€í•œ ë‚´ìš©ì„ ì‘ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.
> - ì•„ë˜ëŠ” AI ëª¨ë¸ì˜ ì´ë¯¸ì§€ í•™ìŠµ ê²°ê³¼ì— ëŒ€í•œ ì¶œë ¥ ë‚´ìš©ì…ë‹ˆë‹¤.

<img src="https://github.com/Kim-src/Images/assets/150884526/13d1bca2-cc95-4c9f-be4c-32cb624a64f8" class="img" alt="figure">

<br>

### ğŸ”” 5. Reference
### ğŸ“Œ GitHub Repository ì£¼ì†Œ
> <a href="https://github.com/Kim-src/VisualCavity">ì‹±í¬í™€(ê³µë™) AI ìë™ ë¶„ì„ í”„ë¡œê·¸ë¨ ê¹ƒí—ˆë¸Œ ë§í¬</a>

<br>

### ğŸ”” 6. Appendix
### ğŸš€ ê°œë°œ í˜„í™© : VisualCavity AI (í˜„ì¬ ver. 0.1.0)
> - v0.1.0 : ì´ë¯¸ì§€ 1ì¥ í•™ìŠµ ì™„ë£Œ (2024-01-09)
> - v0.2.0 : ì´ë¯¸ì§€ 100ì¥ í•™ìŠµ ì™„ë£Œ
> - v0.3.0 : ì´ë¯¸ì§€ 1,000ì¥ í•™ìŠµ ì™„ë£Œ
> - v0.3.3 : ì´ë¯¸ì§€ 1,000ì¥ í•™ìŠµì— ëŒ€í•œ ê²€í†  ì™„ë£Œ
> - v0.3.7 : í•™ìŠµí•œ ì´ë¯¸ì§€ 1,000ì¥ì„ ê°€ì§€ê³  ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ëŒ€ì¡°í•œ ë’¤ ë²„ì „ ë¹„êµ ì™„ë£Œ
> - v0.4.0 : ì´ë¯¸ì§€ 10,000ì¥ í•™ìŠµì— ëŒ€í•œ ê²€í†  ì™„ë£Œ
> - v0.4.3 : ì´ë¯¸ì§€ 10,000ì¥ í•™ìŠµì— ëŒ€í•œ ê²€í†  ì™„ë£Œ
> - v0.4.7 : í•™ìŠµí•œ ì´ë¯¸ì§€ 10,000ì¥ì„ ê°€ì§€ê³  ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ëŒ€ì¡°í•œ ë’¤ ë²„ì „ ë¹„êµ ì™„ë£Œ
> - v0.5.0 : ì´ë¯¸ì§€ 100,000ì¥ í•™ìŠµì— ëŒ€í•œ ê²€í†  ì™„ë£Œ
> - v0.5.3 : ì´ë¯¸ì§€ 100,000ì¥ í•™ìŠµì— ëŒ€í•œ ê²€í†  ì™„ë£Œ
> - v0.5.7 : í•™ìŠµí•œ ì´ë¯¸ì§€ 100,000ì¥ì„ ê°€ì§€ê³  ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ëŒ€ì¡°í•œ ë’¤ ë²„ì „ ë¹„êµ ì™„ë£Œ
> - v0.6.0 : ì´ë¯¸ì§€ 300,000ì¥(ë³´ìœ ì¤‘ì¸ ì´ë¯¸ì§€ ê°œìˆ˜) í•™ìŠµì— ëŒ€í•œ ê²€í†  ì™„ë£Œ
> - v0.6.3 : ì´ë¯¸ì§€ 300,000ì¥ í•™ìŠµì— ëŒ€í•œ ê²€í†  ì™„ë£Œ
> - v0.6.7 : í•™ìŠµí•œ ì´ë¯¸ì§€ 300,000ì¥ì„ ê°€ì§€ê³  ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ëŒ€ì¡°í•œ ë’¤ ë²„ì „ ë¹„êµ ì™„ë£Œ
> - v0.7.0 : ì´ë¯¸ì§€ê°€ í•™ìŠµëœ AI ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ 50m ê¸¸ì´ì˜ íƒì‚¬ ë°ì´í„° ë¶„ì„
> - v0.7.1 : íƒì‚¬ ë°ì´í„° ë¶„ì„ ì„±ê³µë¥  10% ë‹¬ì„±  
>   (ìˆ˜ë§ì€ ì—ëŸ¬ ë°œìƒ ê°€ëŠ¥ì„± ì¦ê°€ ì˜ˆìƒ)
> - v1.0.0 : AIë¥¼ ì´ìš©í•œ ì‹±í¬í™€ ë¶„ì„ ëª¨ë¸ ìƒì„±  
>   (ì‹±í¬í™€ ë¶„ì„ í”„ë¡œê·¸ë¨ì— ë³¸ AI ëª¨ë¸ì„ ì ìš©ì‹œí‚¬ ì˜ˆì •)

<br>
<br>
<br>
